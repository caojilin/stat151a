unins
uninstall.packages
x1
knitr::opts_chunk$set(
cache=TRUE, warning=FALSE, error=FALSE, message=FALSE, echo=TRUE,
results = 'markup', dev='png', dpi=150
)
# uncomment the install.packages if you do not have this package
# install.packages('wooldridge')
require('wooldridge')
data('wage1')
head(wage1)
library(dplyr)
library(ggplot2)
# Recall that wages vary by education, experience, gender, etc.
ggplot(wage1, aes(x= educ, y = log(wage))) + geom_point()+
geom_smooth(method = "lm", se = F)
ggplot(wage1, aes(x= tenure, y = log(wage))) + geom_point()+
geom_smooth(method = "lm", se = F)
ggplot(wage1) + geom_boxplot(aes(x=factor(female), y = log(wage))) +
labs(x = "Gender") + scale_x_discrete(labels = c("Men", "Women"))
ggplot(wage1) + geom_boxplot(aes(x=factor(nonwhite), y = log(wage))) +
labs(x = "Race") + scale_x_discrete(labels = c("White", "Nonwhite"))
model<- lm(lwage~educ+exper+female+nonwhite, data = wage1)
summary(model)
# Compute the coefficient, standard error, t-statistic, and p-value for Education:
X<- as.matrix(cbind(1, wage1[,c("educ", "exper", "female", "nonwhite")]))
y<- wage1$lwage
beta_hat<- solve(t(X) %*% X, t(X) %*% y)
V <- solve(t(X) %*% X)
yhat<- X %*% beta_hat
RSS = sum((y - yhat)^2)
RSE = sqrt(RSS/(526-4-1))
beta_educ<- beta_hat[2]
beta_educ
se_educ<- RSE * sqrt(V[2,2])
se_educ
t_educ<- beta_educ / se_educ
t_educ
pval_educ<- 2*(1-pt(t_educ, 526-4-1))
pval_educ
#compare to what we got from lm():
summary(model)$coefficients[2,]
model1<- lm(lwage~educ + exper, data = wage1)
model2<- lm(lwage~educ + exper + female, data = wage1)
anova(model1, model2)
model3<- lm(lwage~educ + exper + female + nonwhite, data = wage1)
anova(model1, model2, model3)
# use an f-test to compare model 1 and model 2
region_model<- lm(lwage~educ+exper+female+northcen+south+west, data = wage1)
sub_model<- lm(lwage~educ+exper+female, data = wage1)
anova(sub_model, region_model)
# use t-tests to test each of the region coefficients for significance
summary(region_model)
# visualize potential interaction effects:
# no intercept difference, clear interaction
ggplot(wage1, aes(x = tenure, y = lwage)) + geom_point() +
facet_wrap(~nonwhite, scales = "free_x") +
geom_smooth(method = "lm", se = F)
ggplot(wage1, aes(x = exper, y = lwage)) + geom_point() +
facet_wrap(~female, scales = "free_x") +
geom_smooth(method = "lm", se = F)
ggplot(wage1, aes(x = exper, y = lwage)) + geom_point() +
facet_wrap(~trade, scales = "free_x") +
geom_smooth(method = "lm", se = F)
# clear intercept difference, no clear interaction effect
ggplot(wage1, aes(x = educ, y = lwage)) + geom_point() +
facet_wrap(~female, scales = "free_x") +
geom_smooth(method = "lm", se = F)
model<- lm(lwage ~ educ+exper+female+nonwhite+
exper*female + exper*nonwhite, data = wage1)
summary(model)
ggplot(wage1, aes(x= tenure, y = log(wage))) + geom_point()
# How should we model this variable? line or curve?
ggplot(wage1, aes(x= tenure, y = log(wage))) + geom_point()+
geom_smooth(method = "loess", se = F, span = 1) +
geom_smooth(method = "lm", se = F, color = "red")
model<- lm(lwage~educ+tenure+tenursq, data = wage1)
summary(model)
# True parameters (unknown)
beta0 = 32
beta1 = 1.5
beta2 = 0.1
beta3 = 3
# draw data according to the linear regression model.
n_obs <- 100 # number of observations
sig <- 6 # std error of the y's
# draw x's: they will be fixed for our experiment
x1 <- runif(n_obs, 0, 10)
x2 <- round(runif(n_obs, 0, 1))
draw_data <- function(x1, x2, beta0, beta1, beta2, beta3, sig){
n_obs <- length(x1)
# draw y's
y = rnorm(n_obs, mean = beta0 + beta1*x1 + beta2*x2 + beta3*x1*x2, sd = sig)
return(data.frame(x1 = x1, x2 = x2, y = y))
}
dataset <- draw_data(x1,x2, beta0, beta1, beta2, beta3, sig)
head(dataset)
# Compute the regression coefficients from simulated data:
model<- lm(y ~ x1 + x2 + x1*x2, data = dataset)
summary(model)
# notice that estimates are not spot on, but within standard of error
# also x2 is not significant
# draw multiple datasets from the model
# and for each dataset, recompute the regression coefficients.
n_trials <- 200
intercepts <- rep(0, n_trials)
X1_coefs <- X2_coefs <- X1X2_coefs<- rep(0, n_trials)
for(i in 1:n_trials){
dataset <- draw_data(x1, x2, beta0, beta1, beta2, beta3, sig)
model <- lm(y ~ x1 + x2 + x1*x2, data = dataset)
intercepts[i] <- model$coefficients[1]
X1_coefs[i] <- model$coefficients[2]
X2_coefs[i] <- model$coefficients[3]
X1X2_coefs[i]<- model$coefficients[4]
}
# examine distribution of the coefficients
hist(intercepts)
abline(v = beta0, col = "red")
hist(X1_coefs)
abline(v=beta1, col = "red")
hist(X2_coefs)
abline(v=beta2, col = "red")
hist(X1X2_coefs)
abline(v=beta3, col = "red")
lm(y ~ x1 + x2, data = dataset)
# yikes
# run the simulation again, still drawing data from the model y~x1+x2+x1*x2,
# but this time fit a model only on x1+x2
intercepts <- X1_coefs<- X2_coefs<- rep(0, n_trials)
for(i in 1:n_trials){
dataset <- draw_data(x1, x2, beta0, beta1, beta2, beta3, sig)
wrong_model <- lm(y ~ x1+x2, data = dataset)
intercepts[i] <- wrong_model$coefficients[1]
X1_coefs[i] <- wrong_model$coefficients[2]
X2_coefs[i] <- wrong_model$coefficients[3]
}
# see what happens to the coefficients
beta0
mean(intercepts)
beta1
mean(X1_coefs)
beta2
mean(X2_coefs)
hist(intercepts, breaks = 15, xlim = c(min(intercepts), 32))
abline(v = beta0, col = "red")
hist(X1_coefs, breaks = 15, xlim = c(1, max(X1_coefs)))
abline(v = beta1, col = "red")
hist(X2_coefs, breaks = 15, xlim = c(0, max(X2_coefs)))
abline(v = beta2, col = "red")
x1
x2
length(x1)
length(x2)
a= c(1,2,3)
b=c(3,2,1)
a*b
