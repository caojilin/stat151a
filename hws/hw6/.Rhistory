num_class1 = 100
num_class2 = 20
X = matrix(rep(0, (num_class1 + num_class2)*2), ncol=2)
mu1  = c(-3,-3)
sigma1 = diag(2)
mu2  = c(3,3)
sigma2 = matrix(c(1,0,0,2) ,2,2, byrow = T)
for (i in 1:num_class1) {
obsev = mvrnorm(1, mu1, sigma1)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
for (i in num_class1+1:num_class1+num_class2) {
obsev = mvrnorm(1, mu2, sigma2)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
label = c(rep(0,num_class1), rep(1,num_class2))
label
plot(X, col=label+2, main = "Original")
x
X
for (i in (num_class1+1):(num_class1+num_class2)) {
obsev = mvrnorm(1, mu2, sigma2)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
label = c(rep(0,num_class1), rep(1,num_class2))
plot(X, col=label+2, main = "Original")
X = matrix(rep(0, (num_class1 + num_class2)*2), ncol=2)
mu1  = c(-2,-2)
sigma1 = diag(2)
mu2  = c(2,2)
sigma2 = matrix(c(1,0,0,2) ,2,2, byrow = T)
for (i in 1:num_class1) {
obsev = mvrnorm(1, mu1, sigma1)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
for (i in (num_class1+1):(num_class1+num_class2)) {
obsev = mvrnorm(1, mu2, sigma2)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
label = c(rep(0,num_class1), rep(1,num_class2))
plot(X, col=label+2, main = "Original")
X = matrix(rep(0, (num_class1 + num_class2)*2), ncol=2)
mu1  = c(-2,-2)
sigma1 = diag(2)
mu2  = c(1,1)
sigma2 = matrix(c(1,0,0,2) ,2,2, byrow = T)
for (i in 1:num_class1) {
obsev = mvrnorm(1, mu1, sigma1)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
for (i in (num_class1+1):(num_class1+num_class2)) {
obsev = mvrnorm(1, mu2, sigma2)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
label = c(rep(0,num_class1), rep(1,num_class2))
plot(X, col=label+2, main = "Original")
length(which(label == 0))
length(which(label == 1))
label = c(rep(0,num_class1), rep(1,num_class2))
label
num_class1
num_class1 = 1000
num_class2 = 20
X = matrix(rep(0, (num_class1 + num_class2)*2), ncol=2)
mu1  = c(-2,-2)
sigma1 = diag(2)
mu2  = c(1,1)
sigma2 = matrix(c(1,0,0,2) ,2,2, byrow = T)
for (i in 1:num_class1) {
obsev = mvrnorm(1, mu1, sigma1)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
for (i in (num_class1+1):(num_class1+num_class2)) {
obsev = mvrnorm(1, mu2, sigma2)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
label = c(rep(0,num_class1), rep(1,num_class2))
plot(X, col=label+2, main = "Original")
logistic.model = glm(label ~ X , family = "binomial")
20/1000
logistic.model = glm(label ~ X , family = "binomial")
summary(logistic.model)
y_hat = predict(logistic.model, data.frame(X), type = "response")
y_hat = y_hat > 0.5
#traning accuracy
mean(y_hat == label)
library(PRROC)
?prroc
PRROC
?`PRROC-package`
scores.class0 = y_hat[label == 0]
scores.class1 = y_hat[label == 1]
pr.curve(scores.class1, scores.class0)
plot(pr1)
pr1 = pr.curve(scores.class1, scores.class0)
plot(pr1)
pr1 = pr.curve(scores.class1, scores.class0, curve = T)
plot(pr1)
y_hat_prob = predict(logistic.model, data.frame(X), type = "response")
scores.class0 = y_hat_prob[label == 0]
scores.class1 = y_hat_prob[label == 1]
pr1 = pr.curve(scores.class1, scores.class0, curve = T)
plot(pr1)
y_hat_prob = predict(logistic.model, data.frame(X), type = "response")
y_hat = y_hat_prob > 0.5
#traning accuracy
mean(y_hat == label)
scores.class0 = y_hat_prob[label == 0]
scores.class1 = y_hat_prob[label == 1]
pr1 = pr.curve(scores.class1, scores.class0, curve = T)
plot(pr1)
library(caret)
plot(X, col=label+2, main = "Original")
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(arm)
library(PRROC)
library(caret)
set.seed(2)
# multivariate normal data generating
# first experiment, very imbalenced two classes datasets
num_class1 = 1000
num_class2 = 20
X = matrix(rep(0, (num_class1 + num_class2)*2), ncol=2)
mu1  = c(-2,-2)
sigma1 = diag(2)
mu2  = c(1,1)
sigma2 = matrix(c(1,0,0,2) ,2,2, byrow = T)
for (i in 1:num_class1) {
obsev = mvrnorm(1, mu1, sigma1)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
for (i in (num_class1+1):(num_class1+num_class2)) {
obsev = mvrnorm(1, mu2, sigma2)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
label = c(rep(0,num_class1), rep(1,num_class2))
plot(X, col=label+2, main = "Original")
logistic.model = glm(label ~ X , family = "binomial")
summary(logistic.model)
y_hat_prob = predict(logistic.model, data.frame(X), type = "response")
y_hat = y_hat_prob > 0.5
mean(y_hat == label)
scores.class0 = y_hat_prob[label == 0]
scores.class1 = y_hat_prob[label == 1]
pr1 = pr.curve(scores.class1, scores.class0, curve = T)
plot(pr1)
y_hat = y_hat_prob > 0.5
mean(y_hat == label)
confusionMatrix(scores.class0, scores.class1)
confusionMatrix(y_hat, label)
confusionMatrix(y_hat, label)
y_hat
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(y_hat, label)
confusionMatrix(as.factor(y_hat), label)
confusionMatrix(as.factor(y_hat), as.factor(label))
y_hat[which(y_hat == FALSE)] <- 1
y_hat[which(y_hat == TRUE)] <- 0
confusionMatrix(as.factor(y_hat), as.factor(label))
y_hat = y_hat_prob > 0.5
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 1
y_hat[which(y_hat == TRUE)] <- 0
confusionMatrix(as.factor(y_hat), as.factor(label))
as.factor(y_hat)
y_hat = y_hat_prob > 0.5
y_hat
table(y_hat)
confusionMatrix(as.factor(y_hat), as.factor(label))
typeof(y_hat_
typeof(y_hat)
typeof(as.factor(y_hat))
as.factor(label)
y_hat[which(y_hat == FALSE)] <- 1
y_hat[which(y_hat == TRUE)] <- 0
as.factor(y_hat)
table(y_hat)
y_hat = y_hat_prob > 0.5
mean(y_hat == label)
y_hat
table(y_hat)
which(y_hat == TRUE)
y_hat[which(y_hat == TRUE)] <- 1
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
13/20
7/20
13/20
# multivariate normal data generating
# first experiment, very imbalenced two classes datasets
num_class1 = 1000
num_class2 = 20
X = matrix(rep(0, (num_class1 + num_class2)*2), ncol=2)
mu1  = c(-2,-2)
sigma1 = diag(2)
mu2  = c(1,1)
sigma2 = matrix(c(1,0,0,2) ,2,2, byrow = T)
for (i in 1:num_class1) {
obsev = mvrnorm(1, mu1, sigma1)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
for (i in (num_class1+1):(num_class1+num_class2)) {
obsev = mvrnorm(1, mu2, sigma2)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
label = c(rep(1,num_class1), rep(0,num_class2))
plot(X, col=label+2, main = "Original")
logistic.model = glm(label ~ X , family = "binomial")
summary(logistic.model)
y_hat_prob = predict(logistic.model, data.frame(X), type = "response")
scores.class0 = y_hat_prob[label == 1]
scores.class1 = y_hat_prob[label == 0]
pr1 = pr.curve(scores.class1, scores.class0, curve = T)
plot(pr1)
logistic.model = glm(label ~ X , family = "binomial")
summary(logistic.model)
y_hat_prob = predict(logistic.model, data.frame(X), type = "response")
scores.class1 = y_hat_prob[label == 1]
scores.class0 = y_hat_prob[label == 0]
pr1 = pr.curve(scores.class1, scores.class0, curve = T)
plot(pr1)
pr1 = pr.curve(scores.class0, scores.class1, curve = T)
plot(pr1)
y_hat = y_hat_prob > 0.5
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
scores.class0 = y_hat_prob[label == 1]
scores.class1 = y_hat_prob[label == 0]
pr1 = pr.curve(scores.class0, scores.class1, curve = T)
plot(pr1)
?pr.curve
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(arm)
library(PRROC)
library(caret)
# multivariate normal data generating
# first experiment, very imbalenced two classes datasets
set.seed(2)
# multivariate normal data generating
# first experiment, very imbalenced two classes datasets
set.seed(2)
num_class1 = 1000
num_class2 = 20
X = matrix(rep(0, (num_class1 + num_class2)*2), ncol=2)
mu1  = c(-2,-2)
sigma1 = diag(2)
mu2  = c(1,1)
sigma2 = matrix(c(1,0,0,2) ,2,2, byrow = T)
for (i in 1:num_class1) {
obsev = mvrnorm(1, mu1, sigma1)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
for (i in (num_class1+1):(num_class1+num_class2)) {
obsev = mvrnorm(1, mu2, sigma2)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
label = c(rep(1,num_class1), rep(0,num_class2))
plot(X, col=label+2, main = "Original")
logistic.model = glm(label ~ X , family = "binomial")
summary(logistic.model)
y_hat_prob = predict(logistic.model, data.frame(X), type = "response")
scores.class0 = y_hat_prob[label == 1]
scores.class1 = y_hat_prob[label == 0]
pr1 = pr.curve(scores.class0, scores.class1, curve = T)
plot(pr1)
y_hat = y_hat_prob > 0.5
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
13/20
13/15
y_hat = y_hat_prob > 0.7
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
y_hat = y_hat_prob > 0.9
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
y_hat = y_hat_prob > 0.95
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
set.seed(2)
num_class1 = 100000
num_class2 = 2000
X = matrix(rep(0, (num_class1 + num_class2)*2), ncol=2)
mu1  = c(-2,-2)
sigma1 = diag(2)
mu2  = c(1,1)
sigma2 = matrix(c(1,0,0,2) ,2,2, byrow = T)
for (i in 1:num_class1) {
obsev = mvrnorm(1, mu1, sigma1)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
for (i in (num_class1+1):(num_class1+num_class2)) {
obsev = mvrnorm(1, mu2, sigma2)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
label = c(rep(1,num_class1), rep(0,num_class2))
plot(X, col=label+2, main = "Original")
logistic.model = glm(label ~ X , family = "binomial")
summary(logistic.model)
y_hat_prob = predict(logistic.model, data.frame(X), type = "response")
scores.class0 = y_hat_prob[label == 1]
scores.class1 = y_hat_prob[label == 0]
pr1 = pr.curve(scores.class0, scores.class1, curve = T)
plot(pr1)
y_hat = y_hat_prob > 0.5
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
#strick threshold
y_hat = y_hat_prob > 0.9
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
#strick threshold
y_hat = y_hat_prob > 0.95
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
#strick threshold
y_hat = y_hat_prob > 0.99
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
#strick threshold
y_hat = y_hat_prob > 0.95
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
102000 * 0.8
train.index = sample(1:total_size, 0.8*total_size)
total_size = num_class1 + num_class2
train.index = sample(1:total_size, 0.8*total_size)
total_size = num_class1 + num_class2
train.index = sample(1:total_size, 0.8*total_size)
train.feature = X[train.index,]
train.label = label[train.index]
test.feature = X[-train.index,]
test.label = label[-train.index]
table(train.label)
table(test.label)
table(train.label)
table(test.label)
419/(19981+419)
2000/100000
logistic.model = glm(train.label ~ train.feature , family = "binomial")
summary(logistic.model)
y_hat_prob = predict(logistic.model, data.frame(train.feature), type = "response")
scores.class0 = y_hat_prob[label == 1]
scores.class1 = y_hat_prob[label == 0]
pr1 = pr.curve(scores.class0, scores.class1, curve = T)
y_hat_prob
length(y_hat_prob)
scores.class0 = y_hat_prob[train.label == 1]
scores.class1 = y_hat_prob[train.label == 0]
pr1 = pr.curve(scores.class0, scores.class1, curve = T)
plot(pr1)
y_hat = y_hat_prob > 0.5
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
confusionMatrix(as.factor(y_hat), as.factor(train.label))
y_hat = y_hat_prob > 0.95
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(train.label))
y_hat = y_hat_prob > 0.95
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(train.label))
y_hat_prob = predict(logistic.model, data.frame(test.feature), type = "response")
y_hat_prob = predict(logistic.model, newdata=data.frame(test.feature), type = "response")
logistic.model = glm(train.label ~ train.feature , family = "binomial")
y_hat_prob = predict(logistic.model, newdata=data.frame(test.feature), type = "response")
length(y_hat_prob)
nrow(test.feature)
colnames(test.feature)
colnames(train.feature)
colnames(data.frame(train.feature))
colnames(data.frame(test.feature))
logistic.model = glm(train.label ~ data.frame(train.feature) , family = "binomial")
logistic.model = glm(train.label ~ X1 + X2,
data=data.frame(train.feature),
family = "binomial")
summary(logistic.model)
y_hat = y_hat_prob > 0.5
mean(y_hat == label)
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(train.label))
y_hat = y_hat_prob > 0.5
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(train.label))
y_hat = y_hat_prob > 0.95
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(train.label))
y_hat_prob = predict(logistic.model, newdata=data.frame(test.feature), type = "response")
y_hat = y_hat_prob > 0.95
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(test.label))
set.seed(2)
num_class1 = 10000
num_class2 = 200
X = matrix(rep(0, (num_class1 + num_class2)*2), ncol=2)
mu1  = c(-2,-2)
sigma1 = diag(2)
mu2  = c(1,1)
sigma2 = matrix(c(1,0,0,2) ,2,2, byrow = T)
for (i in 1:num_class1) {
obsev = mvrnorm(1, mu1, sigma1)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
for (i in (num_class1+1):(num_class1+num_class2)) {
obsev = mvrnorm(1, mu2, sigma2)
X[i,1] = obsev[1]
X[i,2] = obsev[2]
}
label = c(rep(1,num_class1), rep(0,num_class2))
plot(X, col=label+2, main = "Original")
logistic.model = glm(label ~ X , family = "binomial")
summary(logistic.model)
y_hat_prob = predict(logistic.model, data.frame(X), type = "response")
scores.class0 = y_hat_prob[label == 1]
scores.class1 = y_hat_prob[label == 0]
pr1 = pr.curve(scores.class0, scores.class1, curve = T)
plot(pr1)
y_hat = y_hat_prob > 0.5
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
#strick threshold
y_hat = y_hat_prob > 0.95
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(label))
total_size = num_class1 + num_class2
train.index = sample(1:total_size, 0.8*total_size)
train.feature = X[train.index,]
train.label = label[train.index]
test.feature = X[-train.index,]
test.label = label[-train.index]
# check the ratio of two classes in train and test datasets
table(train.label)
table(test.label)
# they are ok. both have around 0.2 positive(sick people) class
logistic.model = glm(train.label ~ X1 + X2,
data=data.frame(train.feature),
family = "binomial")
summary(logistic.model)
y_hat_prob = predict(logistic.model, data.frame(train.feature), type = "response")
scores.class0 = y_hat_prob[train.label == 1]
scores.class1 = y_hat_prob[train.label == 0]
pr1 = pr.curve(scores.class0, scores.class1, curve = T)
plot(pr1)
y_hat = y_hat_prob > 0.5
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(train.label))
y_hat = y_hat_prob > 0.95
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(train.label))
y_hat = y_hat_prob > 0.95
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(train.label))
y_hat_prob = predict(logistic.model, newdata=data.frame(test.feature), type = "response")
y_hat = y_hat_prob > 0.95
y_hat[which(y_hat == FALSE)] <- 0
y_hat[which(y_hat == TRUE)] <- 1
confusionMatrix(as.factor(y_hat), as.factor(test.label))
